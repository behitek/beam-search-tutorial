{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beam_search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHM1PsLj4OHq",
        "colab_type": "text"
      },
      "source": [
        "# Thực hành với Beam search\n",
        "\n",
        "Khôi phục dấu câu tiếng Việt sử dụng Beam search & Language model\n",
        "\n",
        "> Click vào ảnh để xem bài hướng dẫn chi tiết\n",
        "\n",
        "[![](https://nguyenvanhieu.vn/wp-content/uploads/2020/07/beam-search.jpg)](https://nguyenvanhieu.vn/thuat-toan-beam-search/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_20ohjigege",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import itertools\n",
        "from math import log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L662vkyPgs67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xóa dấu tiếng Việt\n",
        "def remove_vn_accent(s):\n",
        "    s = re.sub('[áàảãạăắằẳẵặâấầẩẫậ]', 'a', s)\n",
        "    s = re.sub('[éèẻẽẹêếềểễệ]', 'e', s)\n",
        "    s = re.sub('[óòỏõọôốồổỗộơớờởỡợ]', 'o', s)\n",
        "    s = re.sub('[íìỉĩị]', 'i', s)\n",
        "    s = re.sub('[úùủũụưứừửữự]', 'u', s)\n",
        "    s = re.sub('[ýỳỷỹỵ]', 'y', s)\n",
        "    s = re.sub('đ', 'd', s)\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1hBPibDgyJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download VN syllables\n",
        "!wget -O vn_syllables.txt \"https://gist.githubusercontent.com/nguyenvanhieuvn/8d7c3440590a6db732ef6e05498c1566/raw/0164ccb7094b22a48a52844e7fa748cf2820cec9/all-vietnamese-syllables.txt(G%25C3%25B5%2520d%25E1%25BA%25A5u%2520ki%25E1%25BB%2583u%2520c%25C5%25A9)\"\n",
        "# Download language model\n",
        "!wget \"https://github.com/nguyenvanhieuvn/vn-accent-resoration/raw/master/vn_en_nextwords.txt.zip\"\n",
        "!unzip vn_en_nextwords.txt.zip\n",
        "# Download test data\n",
        "!wget \"https://github.com/nguyenvanhieuvn/vn-accent-resoration/raw/master/test.txt\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJxEZ3P9hQGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tạo bộ từ điển sinh dấu câu cho các từ không dấu\n",
        "map_accents = {}\n",
        "for word in open('vn_syllables.txt').read().splitlines():\n",
        "  word = word.lower()\n",
        "  no_accent_word = remove_vn_accent(word)\n",
        "  if no_accent_word not in map_accents:\n",
        "    map_accents[no_accent_word] = set()\n",
        "  map_accents[no_accent_word].add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbrvxOJLiKO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "491289a0-ffdd-47d7-b93f-66d3f0641490"
      },
      "source": [
        "print(map_accents['duoc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dước', 'đước', 'đuộc', 'dược', 'duộc', 'được', 'đuốc', 'duốc'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFDH2rCRqCKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dfbdf5b-f8fa-4cbe-e97b-93b3e4a4a2aa"
      },
      "source": [
        "# Đọc lm\n",
        "lm = {}\n",
        "for line in open('vn_en_nextwords.txt'):\n",
        "  data = json.loads(line)\n",
        "  key = data['s']\n",
        "  lm[key] = data\n",
        "vocab_size = len(lm)\n",
        "total_word = 0\n",
        "for word in lm:\n",
        "  total_word += lm[word]['sum']\n",
        "print(vocab_size, total_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 6343849795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S55LZeC_5HMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm['hiếu']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFUYIbcU9LZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tính xác suất dùng smoothing\n",
        "def get_proba(current_word, next_word):\n",
        "  if current_word not in lm:\n",
        "    return 1 / total_word;\n",
        "  if next_word not in lm[current_word]['next']:\n",
        "    return 1 / (lm[current_word]['sum'] + vocab_size)\n",
        "  return (lm[current_word]['next'][next_word] + 1) / (lm[current_word]['sum'] + vocab_size)\n",
        "\n",
        "# def get_proba(current_word, next_word):\n",
        "#   try:\n",
        "#     return (lm[current_word]['next'][next_word]) / (lm[current_word]['sum'])\n",
        "#   except:\n",
        "#     return 1e-30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBQlSHgR34-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hàm beam search\n",
        "def beam_search(words, k=3):\n",
        "  sequences = []\n",
        "  for idx, word in enumerate(words):\n",
        "    if idx == 0:\n",
        "      sequences = [([x], 0.0) for x in map_accents.get(word, [word])]\n",
        "    else:\n",
        "      all_sequences = []\n",
        "      for seq in sequences:\n",
        "        for next_word in map_accents.get(word, [word]):\n",
        "          current_word = seq[0][-1]\n",
        "          proba = get_proba(current_word, next_word)\n",
        "          # print(current_word, next_word, proba, log(proba))\n",
        "          proba = log(proba)\n",
        "          new_seq = seq[0].copy()\n",
        "          new_seq.append(next_word)\n",
        "          all_sequences.append((new_seq, seq[1] + proba))\n",
        "      # print(all_sequences) \n",
        "      all_sequences = sorted(all_sequences,key=lambda x: x[1], reverse=True)\n",
        "      sequences = all_sequences[:k]\n",
        "  return sequences\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko_N1RvRsfbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tiền xử lý text\n",
        "def preprocess(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  sentence = re.sub(r'[.,~`!@#$%\\^&*\\(\\)\\[\\]\\\\|:;\\'\"]+', ' ', sentence)\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARdWnejy38xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "45eb024d-47f1-4803-f7e3-fe984174e5fd"
      },
      "source": [
        "# test 1 câu\n",
        "sentence = \"Tuy nhiên giai đoạn từ 2009 đến ngày 15/10/2017 công ty không còn thực hiện các hoạt động nhập khẩu các mặt hàng thời trang\"\n",
        "sentence = preprocess(sentence)\n",
        "_sentence = remove_vn_accent(sentence)\n",
        "words = _sentence.split()\n",
        "results = beam_search(words, k=5)\n",
        "print('INP:', sentence)\n",
        "\n",
        "print('OUT:', ' '.join(results[0][0]))\n",
        "print('CMP:', ' '.join(results[0][0]) == sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INP: tuy nhiên giai đoạn từ 2009 đến ngày 15/10/2017 công ty không còn thực hiện các hoạt động nhập khẩu các mặt hàng thời trang\n",
            "OUT: tuy nhiên giai đoạn từ 2009 đến ngày 15/10/2017 cổng ty không còn thực hiện các hoạt động nhập khẩu các mặt hàng thời trang\n",
            "CMP: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ87WWXQzQOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bf6b9b54-6ad1-46b0-8757-91686dfbbf09"
      },
      "source": [
        "# test qua bộ test ~ 5000 câu\n",
        "k = 10\n",
        "sentences = open('test.txt').read().splitlines()\n",
        "test_size = len(sentences)\n",
        "print(test_size)\n",
        "correct = 0\n",
        "for sent in sentences:\n",
        "  try:\n",
        "    sent = preprocess(sent)\n",
        "    _sent = remove_vn_accent(sent)\n",
        "    words = _sent.split()\n",
        "    results = beam_search(words, k)\n",
        "    if ' '.join(results[0][0]) == sent:\n",
        "      correct += 1\n",
        "  except:\n",
        "    print('err', sent)\n",
        "    break\n",
        "\n",
        "print(correct / test_size)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4983\n",
            "0.32691149909692957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCpzbFlw2PrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}